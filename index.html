<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<title>Homepage of Hongyuan Zhu</title>

<link rel="stylesheet" href="stylesheets/styles.css">
<link rel="stylesheet" href="stylesheets/pygment_trac.css">
<meta name="viewport" content="width=device-width">
</head>
<body>
<div class="wrapper">

<header>
<h1>Hongyuan Zhu</h1>
<p>
<small>hongyuanzhu.cn (AT) gmail (DOT) com </small><br><br>
<a href="https://dblp.uni-trier.de/pers/hd/z/Zhu:Hongyuan" target="_blank">[DBLP]</a>  <br>
<a href="https://scholar.google.com/citations?user=XTk3sYAAAAAJ&hl=en" target="_blank">[Google Scholar]</a> </p> <br>
<p class="view"><a href="index.html">Homepage</a></p>
<!-- <p class="view"><a href="sub_publication.html">Publications</a><br> -->
<!--<p class="view"><a href="sub_projects.html">Projects</a></p>-->
</header>

<section>

<h2>
<a id="Biography-page" class="anchor" href="#biography-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Brief Bio:</h2>

<p>Hi! My name is Hongyuan Zhu (Chinese: 朱宏远).  I am currently a scientist in the Institute of Infocomm Research (I2R), at the Agency for Science, Technology, and Research (A*STAR), Singapore. I am leading the Advanced Perception Reasoning (APR) lab. I obtained my Ph.D. from Nanyang Technological University (NTU), SG, in 2015 May.  </p>
<hr />
<h2>

<a id="Work-page" class="anchor" href="#work-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Working Experience:</h2>
<ul>
<li><strong>Institut of Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore.</strong>  <br>
- Scientist III, Principal Investigator, Team Lead for Multi-modal Learning and Perception (2021.04-Now)<br>
- Scientist II, Principal Investigator, Research Lead (2019.04-2021.04)<br>
- Scientist I, Principal Investigator (2014.08-2019.04)<br>

<br>
<hr />
<h2>
<a id="reaserch-page" class="anchor" href="#reaserch-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Research Interests:</h2>

<ul>

<li><strong>Low-level Vision</strong>  <br>
- The research on  <em>"Differentiable Physical based Image Enhancement"</em> can be found <a href="proj_dp.html"><font color="#ff0000"> >> HERE </font></a> <br>

<li><strong>Scene Parsing</strong> <br>
- The research on <em>"Semantic Parsing with Various Supervision"</em> can be found <a href="proj_dp.html"><font color="#ff0000"> >> HERE </font></a> <br>

<li><strong>Video Analytics</strong> <br>
 - The research on <em>"Rapid Human Action Detection"</em> can be found <a href="proj_action.html"><font color="#ff0000"> >> HERE </font></a> <br>
 - The research on <em>"Multi-modal Video Question Answering"</em> can be found <a href="proj_videoqa.html"><font color="#ff0000"> >> HERE </font></a> <br>
</ul>

<li><strong>Other Topics @ APR Lab</strong> <br>
 - Feel free to approach me if you would like to collaborate on the topics you are interested. There is no limit to our research topics ;-)


<br>
<hr />

<h2>
<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Recent News:</h2>

<ul>
<li> 2023-02: Three papers accepted by CVPR2023, Congrats to our APR's students: Sijin, Yuanbiao and Yanglin! See you all in Vancouver :) </li>
<li> 2022-11: Congrats to Chuangguan's solid works 3D few-shot learning benchmark accepted by IJCV, Solid works</li>
<li>2022-06: Our team achieve the third place in EPIC KITCHEN Multi-Instance Action Retrieval Challenge, Congrats to Burak! </li>
<li>2022-05: Our team's work on "Unsupervised Contrastive Cross-modal Hashing" is accepted by TPAMI!</li>
<li>2022-04: Congrats to my intern student Mr.Duan Jiafei received A*STAR NSS scholarhip to start research in UW,Seattle! </li>
<li>2022-04: Congrats to my intern student Ms.Huang Ziqi received NTU research scholarhip to start research in NTU S-Lab! </li>
<li>2022-03: Our team is awarded a new 2Mil EDB OSTIN Grant for Satellite Image Analytics. Thanks for the support from EDB! </li>
<li>2022-02: Congrats to Eng Yen's paper on efficient point cloud recogntion accepted by RAL, ICRA2022 track! </li> 
<li>2022-01: Congrats to Xiuchao's first CVPR2022 paper on optical flow estimation! </li>
<li>2022-01: Our developed 1st few-shot point cloud recognition paper is accpeted by WACV22, Congrats to my Mphil Chuanguan! </li>
<li>2021-11: Our developed weakly supervised point cloud instance segmentation using 1000x less labeled date is accepted by PAMI, Congrats to my Mphil YongBin! </li>
<li>2021-10: I receved the A*STAR Career Development Fund and Robot HTPO seed fund ($600K) to develop embodied capabilities, Thanks A*STAR! </li>
<li>2021-09: I'll serve as the Area Chair of ACM MM Asia 2021 at Gold Coast, Australia. </li>>
<li>2021-02: Our A*STAR CHRIS Team is the only team from Asia won the KUKA Innovation Award Finalist! (top5) <a href="https://www.kuka.com/en-sg/company/press/news/2021/02/kuka-innovation-award-finalists-2021" target="_blank"> <strong><ud2>(Link)</ud2></strong></a>
<li>2020-11: Congrats to Hu Peng's paper accepted by AAAI 2021!</li>
<li>2020-09: Appoint as the Associate Editor of Visual Computer, Elsevier</li>
<li>2019-04: One papers <em>"COMIC: Multi-view Clustering Without Parameter Selection"</em> has been accepted by <strong>ICML</strong>.</li>
<li>2019-04: Our ICCV17 extended journal paper <em>"YoTube: Searching Action Proposal via Recurrent and Static Regression Networks"</em> has been selected as ESI Highly Indexed Paper.</li>>
<li>2019-04: I have been invited as a PC member for  CVPR, ICCV, ACM MM, AAAI in 2019.
<li>2019-03: One paper <em>"Spatial Fusion GAN for Image Synthesis"</em> has been accepted by <strong>CVPR 2019</strong>.</li>
<li>2019-03: One paper for <em>"Anomaly Detection in Video Surveillance"</em> has been accepted by <strong>IEEE TIFS</strong>.</li>
<li>2019-01: One paper for <em> </em>have been accepted by <strong>AAAI 2019</strong> as Oral Paper!</li>
<li>2018-11: Our ICCV17 work on action detection has been adversertised as A*STAR Research Highlighted Research among 25 Research Institutes!.</li>
<li><font color="#ff0000">I'm selected as IET Image Processing Special Issue Guest Editor, Call For Paper:</font>  <a href="http://www.pengxi.me/wp-content/uploads/Activity/IET_IP_CFP.pdf" target="_blank"> <strong><ud2>Adversarial Learning in Image Processing</ud2></strong></a> </li>
<li></li>>



</ul>

<hr />
<h2>
<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Academic Activities:</h2>
<ul>


<li> <strong>Professional Activities</strong> <br>-
- Associate Editor: Visual Computer, Elsevier, 09/2020 - Now <br>
- Guest Editor: IET Image Processing, 2018. Guest Editor <br>
- Area Chair: ACM MM Asia, 2022
- Senior Program Committee, IJCAI 2021 <br>
- Session Chair: IJCAI 2018, PCM 2014 <br>
- Journal Reviewer: IEEE TPAMI, TIP, TCSVT, TNNLS, TMM, ACCESS, Elsevier JVCI, CVIU <br>
- Conference Reviewer: CVPR, ICCV, NIPS, ACM MM, AAAI, ACCV, ICME, ICIP, VCIP <br>
</li> 


</ul>
	
<hr />
<h2>
<a id="awards-page" class="anchor" href="#awards-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Awards:</h2>
<ul>
- 2017 International Consortium of Chinese Mathmaticians 2017, Distinguished Paper
- 2014 ICIP14 SPS Travel Grant \& ICIP14 Top-10\% paper award 
- 2014 WACV14 Student Travel Grant 
- 2010 ~ 2014 NTU Graduate Research Scholarship  
- 2010 Ocean-Tech Award for Best Student Final Year Project. 
- 2010 First Prize of IEEE Perl Riverl Delta FYP Competition. 
- 2009 BNU Affinity Card Scholarship(Awarded to top 3 students). 
- 2008 Henry Fork Foundation Scholarship(Awarded to top 3 students).
- 2006 - 2010 Dean's Honor List (Awarded to top $10\%$ students)
</ul>	
	

<br>
<script type="text/javascript" src="//ra.revolvermaps.com/0/0/6.js?i=0mepsvnej83&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>
<a href="https://info.flagcounter.com/3zrz"><img src="https://s01.flagcounter.com/count2/3zrz/bg_FFFFFF/txt_000000/border_CCCCCC/columns_8/maxflags_20/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
	
</section>


</div>
<script src="javascripts/scale.fix.js"></script>
</body>
</html>
